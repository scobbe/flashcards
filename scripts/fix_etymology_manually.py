#!/usr/bin/env python3
"""Manually fix cards by adding etymology explanations.

This script analyzes each card's character breakdown and generates
etymology explanations based on the semantic logic of character combinations.

No API calls - uses embedded logic to generate etymologies.

Usage:
    python scripts/fix_etymology_manually.py [--dry-run]
"""

import re
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from lib.common.utils import is_cjk_char

# Common characters with pinyin and meaning for etymology enrichment
CHAR_INFO = {
    # Radicals and common components
    "Âè£": ("k«íu", "mouth"),
    "Èòø": ("ƒÅ", "prefix"),
    "ÂéÑ": ("√®", "distress"),
    "Â•≥": ("n«ö", "woman"),
    "Â≠ê": ("z«ê", "child"),
    "Êó•": ("r√¨", "sun"),
    "Êúà": ("yu√®", "moon"),
    "Ê∞¥": ("shu«ê", "water"),
    "ÁÅ´": ("hu«í", "fire"),
    "Êú®": ("m√π", "wood"),
    "Èáë": ("jƒ´n", "metal"),
    "Âúü": ("t«î", "earth"),
    "Â±±": ("shƒÅn", "mountain"),
    "‰∫∫": ("r√©n", "person"),
    "ÂøÉ": ("xƒ´n", "heart"),
    "Êâã": ("sh«íu", "hand"),
    "Ë∂≥": ("z√∫", "foot"),
    "ÁõÆ": ("m√π", "eye"),
    "ËÄ≥": ("ƒõr", "ear"),
    "Ë®Ä": ("y√°n", "speech"),
    "È£ü": ("sh√≠", "food"),
    "Ë°£": ("yƒ´", "clothing"),
    "ÈñÄ": ("m√©n", "door"),
    "Èó®": ("m√©n", "door"),
    "Ëªä": ("chƒì", "vehicle"),
    "ËΩ¶": ("chƒì", "vehicle"),
    "È¶¨": ("m«é", "horse"),
    "È©¨": ("m«é", "horse"),
    "È≥•": ("ni«éo", "bird"),
    "È∏ü": ("ni«éo", "bird"),
    "È≠ö": ("y√∫", "fish"),
    "È±º": ("y√∫", "fish"),
    "ËâÆ": ("gƒõn", "stopping"),
    "Ë≤ù": ("b√®i", "shell"),
    "Ë¥ù": ("b√®i", "shell"),
    "ÂΩ≥": ("ch√¨", "step"),
    "Á§∫": ("sh√¨", "show"),
    "Á§ª": ("sh√¨", "spirit"),
    "Á≥∏": ("m√¨", "silk"),
    "Á∫ü": ("sƒ´", "silk"),
    "Á´π": ("zh√∫", "bamboo"),
    "Á±≥": ("m«ê", "rice"),
    "Áæä": ("y√°ng", "sheep"),
    "Áâõ": ("ni√∫", "ox"),
    "Áä¨": ("qu«én", "dog"),
    "Ëô´": ("ch√≥ng", "insect"),
    "Áü≥": ("sh√≠", "stone"),
    "Áî∞": ("ti√°n", "field"),
    "Áöø": ("m«ên", "dish"),
    "ÂàÄ": ("dƒÅo", "knife"),
    "Âäõ": ("l√¨", "power"),
    "Âèà": ("y√≤u", "again"),
    "Â∑•": ("g≈çng", "work"),
    "Â∑±": ("j«ê", "self"),
    "Â∑æ": ("jƒ´n", "cloth"),
    "Âπø": ("gu«éng", "wide"),
    "Âª¥": ("y«ên", "stride"),
    "Âºì": ("g≈çng", "bow"),
    "ÂØ∏": ("c√πn", "inch"),
    "Â∞è": ("xi«éo", "small"),
    "Â§ß": ("d√†", "big"),
    "Â∞∏": ("shƒ´", "corpse"),
    "Âõó": ("w√©i", "enclosure"),
    "Â£´": ("sh√¨", "scholar"),
    "Â§ï": ("xƒ´", "evening"),
    "Ê≠¢": ("zh«ê", "stop"),
    "Êîµ": ("p≈´", "strike"),
    "Êñá": ("w√©n", "writing"),
    "Êñπ": ("fƒÅng", "square"),
    "ÁôΩ": ("b√°i", "white"),
    "Á´ã": ("l√¨", "stand"),
    "Á©¥": ("xu√©", "cave"),
    "ËÇâ": ("r√≤u", "meat"),
    "Ëàå": ("sh√©", "tongue"),
    "Ëæõ": ("xƒ´n", "bitter"),
    "ÈÖâ": ("y«íu", "wine"),
    "Èõ®": ("y«î", "rain"),
    "Èùí": ("qƒ´ng", "blue-green"),
    "Èùû": ("fƒìi", "not"),
    "Èù©": ("g√©", "leather"),
    "È™®": ("g«î", "bone"),
    "È´ò": ("gƒÅo", "tall"),
    "È¨º": ("gu«ê", "ghost"),
    "Èü≥": ("yƒ´n", "sound"),
    "È†Å": ("y√®", "page"),
    "È°µ": ("y√®", "page"),
    "È¢®": ("fƒìng", "wind"),
    "È£é": ("fƒìng", "wind"),
    "È£õ": ("fƒìi", "fly"),
    "È£û": ("fƒìi", "fly"),
    "Èªë": ("hƒìi", "black"),
    "ÈΩí": ("ch«ê", "tooth"),
    "ÈΩø": ("ch«ê", "tooth"),
    "‰∫†": ("t√≥u", "lid"),
    "ÂÜ´": ("bƒ´ng", "ice"),
    "ÂÜñ": ("m√¨", "cover"),
    "Âá†": ("jƒ´", "table"),
    "Âáµ": ("q«î", "receptacle"),
    "Âãπ": ("bƒÅo", "wrap"),
    "Âåï": ("b«ê", "spoon"),
    "Âåö": ("fƒÅng", "box"),
    "Âçú": ("b«î", "divination"),
    "ÂéÇ": ("ch«éng", "cliff"),
    "Âé∂": ("sƒ´", "private"),
    "Â§Ç": ("zh«ê", "go"),
    "Â§ä": ("suƒ´", "go slowly"),
    "ÂÆÄ": ("mi√°n", "roof"),
    "Áàø": ("p√°n", "split wood"),
    "‰∏¨": ("p√°n", "split wood"),
    "Áâá": ("pi√†n", "slice"),
    "Áâô": ("y√°", "tooth"),
    "Áìú": ("guƒÅ", "melon"),
    "Áîò": ("gƒÅn", "sweet"),
    "Áîü": ("shƒìng", "life"),
    "Áî®": ("y√≤ng", "use"),
    "Áñí": ("n√®", "sickness"),
    "Áô∂": ("b≈ç", "footsteps"),
    "ÁöÆ": ("p√≠", "skin"),
    "Áüõ": ("m√°o", "spear"),
    "Áü¢": ("sh«ê", "arrow"),
    "Á¶æ": ("h√©", "grain"),
    "ËÄÅ": ("l«éo", "old"),
    "ËÄå": ("√©r", "and"),
    "ËÄí": ("lƒõi", "plow"),
    "ËÅø": ("y√π", "brush"),
    "Ëá£": ("ch√©n", "minister"),
    "Ëá™": ("z√¨", "self"),
    "Ëá≥": ("zh√¨", "arrive"),
    "Ëáº": ("ji√π", "mortar"),
    "Ëàõ": ("chu«én", "oppose"),
    "Ëàü": ("zh≈çu", "boat"),
    "Ëâ∏": ("c«éo", "grass"),
    "Ë°Ä": ("xu√®", "blood"),
    "Ë°å": ("x√≠ng", "go"),
    "Ë¶ã": ("ji√†n", "see"),
    "ËßÅ": ("ji√†n", "see"),
    "Ëßí": ("ji«éo", "horn"),
    "Ë∞∑": ("g«î", "valley"),
    "Ë±Ü": ("d√≤u", "bean"),
    "Ë±ï": ("sh«ê", "pig"),
    "Ë±∏": ("zh√¨", "beast"),
    "Ë≤ù": ("b√®i", "shell"),
    "Ëµ§": ("ch√¨", "red"),
    "Ëµ∞": ("z«íu", "walk"),
    "Ë∫´": ("shƒìn", "body"),
    "Ëæ∞": ("ch√©n", "time"),
    "ÈÇë": ("y√¨", "city"),
    "Èï∑": ("ch√°ng", "long"),
    "Èïø": ("ch√°ng", "long"),
    "Èòú": ("f√π", "mound"),
    "Èö∂": ("l√¨", "slave"),
    "Èöπ": ("zhuƒ´", "short-tailed bird"),
    "Èù¢": ("mi√†n", "face"),
    "Èüã": ("w√©i", "leather"),
    "Èü≠": ("ji«î", "leek"),
    "È¶ñ": ("sh«íu", "head"),
    "È¶ô": ("xiƒÅng", "fragrant"),
    "Èºì": ("g«î", "drum"),
    "Èº†": ("sh«î", "rat"),
    "Èºª": ("b√≠", "nose"),
    "‰∫¶": ("y√¨", "also"),
    "‰∫§": ("jiƒÅo", "exchange"),
    "‰∫¨": ("jƒ´ng", "capital"),
    "‰ª§": ("l√¨ng", "order"),
    "ÂÖÜ": ("zh√†o", "omen"),
    "ÂÖ±": ("g√≤ng", "together"),
    "ÂåÖ": ("bƒÅo", "wrap"),
    "Âçä": ("b√†n", "half"),
    "Âçë": ("bƒìi", "low"),
    "Âç†": ("zh√†n", "occupy"),
    "Âè¨": ("zh√†o", "summon"),
    "ÂèØ": ("kƒõ", "can"),
    "Âè∞": ("t√°i", "platform"),
    "Âêå": ("t√≥ng", "same"),
    "Âêë": ("xi√†ng", "toward"),
    "Âêæ": ("w√∫", "I"),
    "Âë®": ("zh≈çu", "circle"),
    "ÂìÅ": ("p«ên", "product"),
    "Âì°": ("yu√°n", "member"),
    "Âëò": ("yu√°n", "member"),
    "Âîê": ("t√°ng", "Tang"),
    "ÂñÑ": ("sh√†n", "good"),
    "Âñú": ("x«ê", "joy"),
    "Âçï": ("dƒÅn", "single"),
    "ÂñÆ": ("dƒÅn", "single"),
    "‰∏•": ("y√°n", "strict"),
    "Âö¥": ("y√°n", "strict"),
    "Âú£": ("sh√®ng", "holy"),
    "ËÅñ": ("sh√®ng", "holy"),
    "Â∏ù": ("d√¨", "emperor"),
    "Âπ∂": ("b√¨ng", "combine"),
    "Ê•≠": ("y√®", "business"),
    "‰∏ö": ("y√®", "business"),
    "Êù±": ("d≈çng", "east"),
    "‰∏ú": ("d≈çng", "east"),
    "ÂêÑ": ("g√®", "each"),
    "Ê≠£": ("zh√®ng", "correct"),
    "Êüê": ("m«íu", "certain"),
    "Ê¨°": ("c√¨", "time"),
    "ÊÆ≥": ("sh≈´", "weapon"),
    "ÊØî": ("b«ê", "compare"),
    "Ê∞ë": ("m√≠n", "people"),
    "Ê∞è": ("sh√¨", "clan"),
    "Ê∞î": ("q√¨", "air"),
    "Ê∞£": ("q√¨", "air"),
    "Ê±Ç": ("qi√∫", "seek"),
    "Ê±á": ("hu√¨", "gather"),
    "Ê±†": ("ch√≠", "pool"),
    "Ê≤°": ("m√©i", "not have"),
    "Ê≥ï": ("f«é", "law"),
    "Ê¥ã": ("y√°ng", "ocean"),
    "Ê∑±": ("shƒìn", "deep"),
    "Ê∏Ö": ("qƒ´ng", "clear"),
    "Êª°": ("m«én", "full"),
    "Êªø": ("m«én", "full"),
    "ÁÑ∂": ("r√°n", "thus"),
    "Êó†": ("w√∫", "without"),
    "ÁÑ°": ("w√∫", "without"),
    "Áéã": ("w√°ng", "king"),
    "Áéâ": ("y√π", "jade"),
    "Áîö": ("sh√®n", "very"),
    "Áî±": ("y√≥u", "from"),
    "Áî≥": ("shƒìn", "extend"),
    "Áî∑": ("n√°n", "male"),
    "Áïú": ("ch√π", "livestock"),
    "Áï™": ("fƒÅn", "foreign"),
    "Áïè": ("w√®i", "fear"),
    "Áúü": ("zhƒìn", "true"),
    "Áúû": ("zhƒìn", "true"),
    "Áßã": ("qi≈´", "autumn"),
    "Á©Ä": ("g«î", "grain"),
    "Á©∫": ("k≈çng", "empty"),
    "Á≠â": ("dƒõng", "wait"),
    "ÁØÄ": ("ji√©", "festival"),
    "ËäÇ": ("ji√©", "festival"),
    "Á¥Ñ": ("yuƒì", "Á∫¶"),
    "Á∫¶": ("yuƒì", "Á∫¶"),
    "ÁæΩ": ("y«î", "feather"),
    "Áøº": ("y√¨", "wing"),
    "ËÉΩ": ("n√©ng", "able"),
    "ËÉå": ("b√®i", "back"),
    "ËÉÉ": ("w√®i", "stomach"),
    "Ëà¨": ("bƒÅn", "sort"),
    "ËâØ": ("li√°ng", "good"),
    "Ëâ≤": ("s√®", "color"),
    "Ëçâ": ("c«éo", "grass"),
    "ËèØ": ("hu√°", "Chinese"),
    "Âçé": ("hu√°", "Chinese"),
    "Ëôé": ("h«î", "tiger"),
    "Ë•ø": ("xƒ´", "west"),
    "Ë¶Å": ("y√†o", "want"),
    "Ë®±": ("x«î", "permit"),
    "ËÆ∏": ("x«î", "permit"),
    "Ë∞∑": ("g«î", "valley"),
    "Ë±°": ("xi√†ng", "elephant"),
    "Ë≤†": ("f√π", "bear"),
    "Ë¥ü": ("f√π", "bear"),
    "Ëæ≤": ("n√≥ng", "agriculture"),
    "ÂÜú": ("n√≥ng", "agriculture"),
    "Ëøë": ("j√¨n", "near"),
    "ÈÄ≤": ("j√¨n", "advance"),
    "Ëøõ": ("j√¨n", "advance"),
    "ÈÄ£": ("li√°n", "connect"),
    "Ëøû": ("li√°n", "connect"),
    "ÈÅì": ("d√†o", "way"),
    "Èáå": ("l«ê", "mile"),
    "Èáè": ("li√†ng", "quantity"),
    "Èóú": ("guƒÅn", "close"),
    "ÂÖ≥": ("guƒÅn", "close"),
    "Èùí": ("qƒ´ng", "green"),
    "Èùú": ("j√¨ng", "quiet"),
    "Èùô": ("j√¨ng", "quiet"),
    "È†≠": ("t√≥u", "head"),
    "Â§¥": ("t√≥u", "head"),
    "È°å": ("t√≠", "topic"),
    "È¢ò": ("t√≠", "topic"),
    "È°Ø": ("xi«én", "show"),
    "Êòæ": ("xi«én", "show"),
    "È¶¨": ("m«é", "horse"),
    "‰Ωì": ("t«ê", "body"),
    "È´î": ("t«ê", "body"),
}


def enrich_etymology_with_pinyin(etymology: str) -> str:
    """Add pinyin and meaning to character references in etymology that are missing them.
    
    Transforms patterns like:
    - Âè£ ("mouth") -> Âè£ (k«íu, "mouth")  
    - Âè£ + phonetic Èòø -> Âè£ (k«íu, "mouth") + phonetic Èòø (ƒÅ, "prefix")
    """
    if not etymology:
        return etymology
    
    result = etymology
    
    # Find all CJK characters that might need enrichment
    # Pattern: character followed by optional space and ( or + or end
    for char in CHAR_INFO:
        if char not in result:
            continue
        
        pinyin, meaning = CHAR_INFO[char]
        
        # Pattern 1: char ("meaning") without pinyin -> char (pinyin, "meaning")
        pattern1 = re.compile(rf'{re.escape(char)}\s*\("([^"]+)"\)')
        if pattern1.search(result):
            result = pattern1.sub(rf'{char} ({pinyin}, "\1")', result)
            continue
        
        # Pattern 2: char followed by space and + or . (phonetic component without any info)
        # e.g., "phonetic Èòø ." or "phonetic Èòø +"
        pattern2 = re.compile(rf'(phonetic\s+){re.escape(char)}(\s*[.+])')
        if pattern2.search(result):
            result = pattern2.sub(rf'\g<1>{char} ({pinyin}, "{meaning}")\2', result)
            continue
        
        # Pattern 3: "semantic Âè£" without parentheses
        pattern3 = re.compile(rf'(semantic\s+){re.escape(char)}(\s+[^(])')
        if pattern3.search(result):
            result = pattern3.sub(rf'\g<1>{char} ({pinyin}, "{meaning}")\2', result)
    
    return result


def parse_card(content: str) -> Dict:
    """Parse a card's content into structured data."""
    result = {
        "headword": "",
        "headword_trad": "",
        "pinyin": "",
        "definition": "",
        "characters": [],  # List of (char, trad, pinyin, english)
        "has_etymology": False,
        "etymology": "",
        "examples": [],
        "raw_lines": content.split("\n"),
    }
    
    lines = content.split("\n")
    
    # Parse headword
    for line in lines:
        if line.startswith("## "):
            hw = line[3:].strip()
            # Check for traditional in parens
            match = re.match(r'^([^(]+)\(([^)]+)\)$', hw)
            if match:
                result["headword"] = match.group(1).strip()
                result["headword_trad"] = match.group(2).strip()
            else:
                result["headword"] = hw
                result["headword_trad"] = ""
            break
    
    # Parse pinyin
    for line in lines:
        if "**pinyin:**" in line:
            result["pinyin"] = line.split("**pinyin:**")[1].strip()
            break
    
    # Parse definition
    for line in lines:
        if "**definition:**" in line:
            result["definition"] = line.split("**definition:**")[1].strip()
            break
    
    # Check for etymology
    result["has_etymology"] = any("**etymology:**" in line for line in lines)
    
    # Parse characters section
    # Format is:
    #   - Âçé(ËèØ)
    #     - hu√°
    #     - Chinese
    in_chars = False
    current_char = None
    char_data = []
    sub_items = []
    saved_last = False
    
    for i, line in enumerate(lines):
        if "**characters:**" in line:
            in_chars = True
            continue
        if in_chars:
            # Check for end of characters section
            if line.startswith("- **") and "characters" not in line:
                # Save last character
                if current_char and len(sub_items) >= 2:
                    current_char["pinyin"] = sub_items[0]
                    current_char["english"] = sub_items[1] if len(sub_items) > 1 else ""
                    char_data.append(current_char)
                    saved_last = True
                in_chars = False
                current_char = None
                continue
            
            # Character line (2 spaces, dash, space)
            if line.startswith("  - ") and not line.startswith("    "):
                # Save previous character
                if current_char and len(sub_items) >= 2:
                    current_char["pinyin"] = sub_items[0]
                    current_char["english"] = sub_items[1] if len(sub_items) > 1 else ""
                    char_data.append(current_char)
                
                # Start new character
                sub_items = []
                char_text = line[4:].strip()
                # Parse char(trad) format
                match = re.match(r'^([^(]+)\(([^)]+)\)$', char_text)
                if match:
                    current_char = {"char": match.group(1).strip(), "trad": match.group(2).strip(), "pinyin": "", "english": ""}
                else:
                    current_char = {"char": char_text, "trad": "", "pinyin": "", "english": ""}
            
            # Sub-item line (4 spaces, dash, space)
            elif line.startswith("    - ") and current_char:
                text = line[6:].strip()
                sub_items.append(text)
    
    # Save last character if not already saved
    if current_char and len(sub_items) >= 2 and not saved_last:
        current_char["pinyin"] = sub_items[0]
        current_char["english"] = sub_items[1] if len(sub_items) > 1 else ""
        char_data.append(current_char)
    
    result["characters"] = char_data
    return result


def format_char_reference(char: str, trad: str, pinyin: str, english: str) -> str:
    """Format a character reference with proper format.
    
    Format: simplified(traditional) (pinyin, "meaning") or simplified (pinyin, "meaning")
    """
    # Get primary meaning (before first semicolon, take first comma-separated item)
    primary = english.split(";")[0].split(",")[0].strip()
    
    if trad and trad != char:
        return f'{char}({trad}) ({pinyin}, "{primary}")'
    else:
        return f'{char} ({pinyin}, "{primary}")'


def generate_multi_char_etymology_openai(
    headword: str, 
    headword_trad: str, 
    pinyin: str, 
    definition: str, 
    characters: List[Dict]
) -> str:
    """Use OpenAI to generate insightful etymology for multi-character words."""
    from lib.common.openai import OpenAIClient
    
    # Build character context
    char_info = []
    for c in characters:
        char = c.get("char", "")
        trad = c.get("trad", "")
        char_pinyin = c.get("pinyin", "")
        eng = c.get("english", "")
        if char:
            if trad and trad != char:
                char_info.append(f"{char}({trad}) [{char_pinyin}]: {eng}")
            else:
                char_info.append(f"{char} [{char_pinyin}]: {eng}")
    
    char_context = "\n".join(char_info)
    
    system = """You are an expert in Chinese etymology and word formation.
For this multi-character word, explain WHY these characters together create this meaning.

Provide REAL INSIGHT - not just "combines X with Y". Explain:
- The semantic logic or metaphor behind the combination
- Historical or cultural context if relevant
- Why this particular combination makes sense

Return JSON: {"etymology": "Your insightful 1-2 sentence explanation..."}

CRITICAL RULES:
- When referencing a character, ALWAYS use format: Â≠ó(ÂÇ≥Áµ±) (pƒ´nyƒ´n, "meaning") or Â≠ó (pƒ´nyƒ´n, "meaning") if traditional is same
- Example: Êòü (xƒ´ng, "star") and Êúü (qƒ´, "period") together reference the seven-day cycle named after celestial bodies.
- Be concise but insightful - explain the WHY, not just the WHAT
- Do NOT start with "Combines..." or "The word..." - jump straight into the insight"""

    user = f"""Word: {headword}"""
    if headword_trad and headword_trad != headword:
        user += f" (traditional: {headword_trad})"
    user += f"""
Pinyin: {pinyin}
Meaning: {definition}

Component characters:
{char_context}"""

    try:
        client = OpenAIClient()
        data = client.complete_json(system, user)
        etymology = str(data.get("etymology", "")).strip()
        if etymology:
            # Ensure it ends with a period
            if not etymology.endswith('.'):
                etymology += '.'
            return etymology
    except Exception as e:
        print(f"    [warn] OpenAI etymology failed for {headword}: {e}")
    
    return ""


def generate_etymology(headword: str, headword_trad: str, pinyin: str, definition: str, characters: List[Dict]) -> str:
    """Generate etymology explanation based on character meanings.
    
    Uses format: simplified(traditional) (pinyin, "meaning") for character references.
    """
    # Count CJK characters in headword
    cjk_count = sum(1 for ch in headword if is_cjk_char(ch))
    
    # Single character - generate etymology based on character structure
    if cjk_count == 1:
        return generate_single_char_etymology(headword, headword_trad, pinyin, definition)
    
    # Multi-character word - use OpenAI for insightful etymology
    if characters:
        openai_etym = generate_multi_char_etymology_openai(
            headword, headword_trad, pinyin, definition, characters
        )
        if openai_etym:
            return openai_etym
    
    # Fallback if no characters or OpenAI failed
    return ""


def fetch_wiktionary_etymology(char: str) -> str:
    """Fetch etymology/glyph origin from Wiktionary for a character."""
    from lib.output.html import fetch_wiktionary_html_status, sanitize_html
    import re
    
    html, status = fetch_wiktionary_html_status(char)
    if status != 200 or not html:
        return ""
    
    # Parse and extract etymology
    parsed = sanitize_html(html)
    
    etymology_text = ""
    
    # Try to find Glyph origin section - look for "Phono-semantic compound" or similar patterns
    # These patterns indicate actual etymology content
    patterns = [
        # Phono-semantic compound explanation
        r'Phono-semantic compound[^.]+\.',
        # Ideogrammic compound
        r'Ideogrammic compound[^.]+\.',
        # Pictogram
        r'Pictogram[^.]+\.',
        # From X
        r'From [^.]+\.',
        # Semantic X + phonetic Y
        r'semantic [^+]+ \+ phonetic [^.]+\.',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, parsed, re.IGNORECASE)
        if match:
            etymology_text = match.group(0).strip()
            break
    
    # If no specific pattern found, try to get the Glyph origin section
    if not etymology_text:
        glyph_match = re.search(r'Glyph origin:\s*(.+?)(?=Etymology:|Definitions:|Pronunciation:|Chinese content:|$)', parsed, re.DOTALL)
        if glyph_match:
            content = glyph_match.group(1).strip()
            # Look for the most informative part (usually starts with Phono-, Ideo-, Picto-, From)
            for pattern in patterns:
                match = re.search(pattern, content, re.IGNORECASE)
                if match:
                    etymology_text = match.group(0).strip()
                    break
    
    # Try to extract phonetic series info if still nothing
    if not etymology_text:
        # Look for "phonetic series" which lists related characters
        phonetic_match = re.search(r'phonetic series\s*\(\s*([^\)]+)\s*\)', parsed, re.IGNORECASE)
        if phonetic_match:
            phonetic_char = phonetic_match.group(1).strip()
            # Check if this character has Âè£ (mouth) radical - common for interjections
            if 'Âè£' in parsed[:500]:
                etymology_text = f"Phono-semantic compound: semantic Âè£ (\"mouth\") + phonetic {phonetic_char}"
    
    # Clean up the text
    if etymology_text:
        # Remove OC pronunciation notations like (OC *qreÀê…°)
        etymology_text = re.sub(r'\s*\(\s*OC\s+\*[^)]+\)', '', etymology_text)
        # Remove wiki markup artifacts
        etymology_text = re.sub(r'\[\d+\]', '', etymology_text)
        # Remove citation references like (Pulleyblank, 1995)
        etymology_text = re.sub(r'\s*\([^)]*\d{4}[^)]*\)', '', etymology_text)
        # Clean up Chinese form notation
        etymology_text = re.sub(r'\s*\(\s*ÂΩ¢ËÅ≤\s*/\s*ÂΩ¢Â£∞[^)]*\)', '', etymology_text)
        etymology_text = re.sub(r'\s*\(\s*ÊúÉÊÑè\s*/\s*‰ºöÊÑè[^)]*\)', '', etymology_text)
        etymology_text = re.sub(r'\s*\(\s*Ë±°ÂΩ¢[^)]*\)', '', etymology_text)
        # Clean whitespace
        etymology_text = re.sub(r'\s+', ' ', etymology_text).strip()
        # Normalize curly quotes to straight quotes (U+201C left, U+201D right)
        etymology_text = etymology_text.replace('\u201c', '"').replace('\u201d', '"')
        # Format quotes properly: ( " X " ) -> ("X")
        etymology_text = re.sub(r'\(\s*"\s*', '("', etymology_text)
        etymology_text = re.sub(r'\s*"\s*\)', '")', etymology_text)
        # Clean up any remaining spacing issues around parens
        etymology_text = re.sub(r'\s+\(', ' (', etymology_text)
        etymology_text = re.sub(r'\(\s+', '(', etymology_text)
        etymology_text = re.sub(r'\s+\)', ')', etymology_text)
        # Clean up trailing spaces before period
        etymology_text = re.sub(r'\s+\.', '.', etymology_text)
        # Ensure proper capitalization
        if etymology_text and etymology_text[0].islower():
            etymology_text = etymology_text[0].upper() + etymology_text[1:]
        # Remove trailing period if present, we'll add our own
        etymology_text = etymology_text.rstrip('.')
        # Add period at end
        if etymology_text and not etymology_text.endswith('.'):
            etymology_text += '.'
    
    # Enrich with pinyin and meanings for referenced characters
    etymology_text = enrich_etymology_with_pinyin(etymology_text)
    
    return etymology_text


def generate_single_char_etymology(char: str, trad: str, pinyin: str, definition: str) -> str:
    """Generate etymology for a single character by fetching from Wiktionary."""
    # Try to fetch from Wiktionary
    wiki_etym = fetch_wiktionary_etymology(char)
    if wiki_etym:
        return wiki_etym
    
    # If traditional is different, try that too
    if trad and trad != char:
        wiki_etym = fetch_wiktionary_etymology(trad)
        if wiki_etym:
            return wiki_etym
    
    # Fallback - generic description
    trad_part = f"({trad})" if trad and trad != char else ""
    return f"A character{trad_part} meaning {definition.lower().rstrip('.')}."


def fix_card(content: str, force_refix: bool = False) -> Tuple[str, bool]:
    """Fix a card by adding or updating etymology.
    
    Args:
        content: Card markdown content
        force_refix: If True, re-fetch etymology even if card already has one
    
    Returns (new_content, was_modified).
    """
    card = parse_card(content)
    
    # Skip if already has etymology (unless force_refix)
    if card["has_etymology"] and not force_refix:
        return content, False
    
    # Generate etymology
    etymology = generate_etymology(
        card["headword"], 
        card["headword_trad"], 
        card["pinyin"], 
        card["definition"], 
        card["characters"]
    )
    
    if not etymology:
        return content, False
    
    # Insert etymology in the right place
    lines = content.split("\n")
    
    # If force_refix, remove existing etymology line first
    if force_refix:
        lines = [line for line in lines if "**etymology:**" not in line]
    
    new_lines = []
    inserted = False
    
    # Check if card has characters section
    has_chars_section = any("**characters:**" in line for line in lines)
    
    if has_chars_section:
        # Insert after characters section, before examples
        in_chars = False
        for i, line in enumerate(lines):
            new_lines.append(line)
            
            if "**characters:**" in line:
                in_chars = True
            elif in_chars and line.startswith("- **") and "characters" not in line:
                # Found next section after characters - insert etymology before it
                new_lines.insert(-1, f"- **etymology:** {etymology}")
                inserted = True
                in_chars = False
    else:
        # No characters section - insert after definition, before examples
        for i, line in enumerate(lines):
            new_lines.append(line)
            
            if "**definition:**" in line and not inserted:
                # Check if next line is indented (multi-line definition)
                next_idx = i + 1
                while next_idx < len(lines) and lines[next_idx].startswith("  - "):
                    next_idx += 1
                # We're past the definition, but we already appended this line
                # So we add etymology right after this line
                if next_idx == i + 1:
                    # Single line definition - insert right after
                    new_lines.append(f"- **etymology:** {etymology}")
                    inserted = True
            elif "**examples:**" in line and not inserted:
                # Insert before examples if we haven't yet
                new_lines.insert(-1, f"- **etymology:** {etymology}")
                inserted = True
    
    if not inserted:
        return content, False
    
    return "\n".join(new_lines), True


def process_directory(output_dir: Path, dry_run: bool = False, force_refix: bool = False) -> Tuple[int, int]:
    """Process all cards in a directory.
    
    Returns (total_cards, cards_fixed).
    """
    total = 0
    fixed = 0
    
    for md_file in sorted(output_dir.glob("*.md")):
        if md_file.name.startswith("-"):
            continue
        
        total += 1
        content = md_file.read_text(encoding="utf-8")
        new_content, was_fixed = fix_card(content, force_refix=force_refix)
        
        if was_fixed:
            fixed += 1
            if not dry_run:
                md_file.write_text(new_content, encoding="utf-8")
            print(f"  ‚úì Fixed: {md_file.name}")
    
    return total, fixed


def main():
    dry_run = "--dry-run" in sys.argv
    force_refix = "--force" in sys.argv
    
    project_root = Path(__file__).parent.parent
    output_root = project_root / "output"
    
    mode_str = ""
    if dry_run:
        mode_str = "[DRY RUN] "
    if force_refix:
        mode_str += "[FORCE REFIX] "
    
    print(f"{mode_str}Fixing cards with missing etymology...")
    print("=" * 60)
    
    total_cards = 0
    total_fixed = 0
    
    # Find all Chinese output directories
    for output_dir in sorted(output_root.rglob("output")):
        if not output_dir.is_dir():
            continue
        
        # Skip English directories
        if "english" in str(output_dir):
            continue
        
        # Check if has .md files
        md_files = [f for f in output_dir.glob("*.md") if not f.name.startswith("-")]
        if not md_files:
            continue
        
        rel_path = output_dir.relative_to(project_root)
        print(f"\nüìÅ {rel_path}")
        
        cards, fixed = process_directory(output_dir, dry_run=dry_run, force_refix=force_refix)
        total_cards += cards
        total_fixed += fixed
        
        if fixed == 0:
            print("  (no fixes needed)")
    
    print("\n" + "=" * 60)
    print(f"{mode_str}COMPLETE")
    print(f"Total cards: {total_cards}")
    print(f"Cards fixed: {total_fixed}")


if __name__ == "__main__":
    main()

